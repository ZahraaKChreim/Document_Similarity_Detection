# from nltk.tokenize import sent_tokenize, word_tokenize
# import networkx as nx
# import matplotlib.pyplot as plt
# import multiprocessing as mp
# import typing


# class Graph:

#     def __init__(self):
#         self.graph = nx.DiGraph()

#     def build_graph(self, sentences):

#         seen_words = []
#         edges = {}
#         final_edges = []
#         for sentence in sentences:
#             words = sentence.split(" ")
#             for i in range(len(words)):
#                 if i != (range(len(words))-1):
                    